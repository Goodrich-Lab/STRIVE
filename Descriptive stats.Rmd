---
title: 'STRIVE'
subtitle: "Descriptive Stats"
author: "Hongxu Wang"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, echo=FALSE}
options(knitr.table.format = "html")
options(scipen = 999) 
knitr::opts_chunk$set(echo = TRUE)

source(fs::path(here::here("!libraries.R")))
source(fs::path(here::here("!directories.R")))
source(fs::path(here::here("!load_cleaned_data.R")))
```


```{r data summary,warning=FALSE}
#data1 <- data %>% drop_na(case_control) %>% dyplr::select(-strive_id,-contains("scld")) %>%
 # mutate_at(.vars = potential_conf[-2],
  #          .funs = ~ as.character(.))
# 
# table1::table1(~.|case_control, data1)
```

# Check percentage of NA for each PFAS
```{r percentage of NA, warning=FALSE}
data_pfas<- data %>% dplyr::select(pfas_name, -contains("scld"))

## Stats----
pfas_na <- data_pfas %>% 
  pivot_longer(cols = pfas_name) %>%
  group_by(name) %>%
  dplyr::summarize(pct_na = sum(is.na(value))/dim(data_pfas)[1])%>%
  ungroup()%>%
  arrange(pct_na)

print(pfas_na, n=25) #n=25

correlation_matrix <- data_pfas %>%
  select_if(~sum(!is.na(.)) > 0) %>%  # Ensure there is at least some non-missing data
  cor(use = "pairwise.complete.obs")

print(correlation_matrix)

correlation_long <- melt(correlation_matrix)

heatmap_plot <- ggplot(data = correlation_long, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 8, hjust = 1)) +
  coord_fixed() +
  labs(x = "PFAS", y = "PFAS", title = "Correlation Heatmap of PFAS Variables")

print(heatmap_plot)

##scaled 14 PFAS
data_pfas1<- data %>% dplyr::select(contains("scld"))

correlation_matrix1 <- data_pfas1 %>%
  select_if(~sum(!is.na(.)) > 0) %>%  
  cor(use = "pairwise.complete.obs")

print(correlation_matrix1)
correlation_long1 <- melt(correlation_matrix1)

heatmap_plot1 <- ggplot(data = correlation_long1, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 8, hjust = 1)) +
  coord_fixed() +
  labs(x = "PFAS", y = "PFAS", title = "Correlation Heatmap of Scaled PFAS Variables")
print(heatmap_plot1)

```

# Descriptive stats of PFAS in overall paricipants
```{r descriptive stats for pfas, warning=FALSE}
data_pfas<- data %>% dplyr::select(pfas_name_analysis)

## Stats----
(pfas_stats <- data_pfas %>% 
  pivot_longer(cols = pfas_name_analysis) %>%
  drop_na() %>%
  group_by(name) %>%
  dplyr::summarise(
    geometric_mean = jag2::fungm(value),
    sd = jag2::fungsd(value),
    min = min(value),
    max = max(value),
    percentile_25 = jag2::qntle_fxn(value, 0.25),
    percentile_50 = jag2::qntle_fxn(value, 0.5),
    percentile_75 = jag2::qntle_fxn(value, 0.75),
    percentile_90 = jag2::qntle_fxn(value, 0.90)
  ) %>% 
  ungroup())

#writexl::write_xlsx(pfas_stats,
 #                   fs::path(dir_result,
     #                        "descriptive_stats_pfas.xlsx"))
```

# Process of selecting outcome variables
```{r}
#1. ALT
num_na_alt <- sum(is.na(data$alt_u_l))
cat("Print: the number of NA in ALT=", num_na_alt)
cat("Print: percentage of NA in ALT=", (num_na_alt/dim(data)[1])*100)

# 1-1. check the distribution of ALT
alt_clean <- na.omit(data$alt_u_l) # Remove missing values

min_alt <- min(alt_clean)# Calculate range
max_alt <- max(alt_clean)
mean_alt <- mean(alt_clean)# Calculate mean
sd_alt <- sd(alt_clean)# Calculate standard deviation

cat("Print: range of ALT=", min_alt," and ",max_alt, "\n")
cat("Print: mean and SD of ALT=", mean_alt," and ", sd_alt, "\n")

# Redraw the plot with extended axis limits
plotNormalHistogram(alt_clean, 
                    prob = FALSE, 
                    col = "white", 
                    border = "black", 
                    main = "Distribution of ALT(u/l)",
                    xlab = "ALT(u/l)",
                    ylab = "Number of samples",
                    linecol = "red", 
                    lwd = 3
                    )
              
density_data <- density(alt_clean)# Calculate density

hist_data <- hist(alt_clean, plot = FALSE) # Create the histogram to get the breaks for scaling the density

density_scaled <- density_data$y * diff(hist_data$mids[1:2]) * length(alt_clean) # Scale density values to match the histogram frequency

# Add density lines
lines(density_data$x, density_scaled, col = "blue", lwd = 2)

# Add legend
legend("topright", 
       legend = c("Normal Distribution", "Density"), 
       col = c("red", "blue"), 
       lwd = 3, 
       cex = 0.8, 
       bty = "n")



# 1-2. check the distribution of ln(ALT), based on the distribution of ALT, which needs natural log transformation.

num_na_ln_alt <- sum(is.na(data$log_alt)) #check the na
cat("Print: the number of NA in Ln ALT=", num_na_ln_alt, "\n")
cat("Print: percentage of NA in Ln ALT=", (num_na_ln_alt/dim(data)[1])*100,"\n")

ln_alt_clean <- na.omit(data$log_alt) # Remove missing values

min_ln_alt <- min(ln_alt_clean)# Calculate range
max_ln_alt <- max(ln_alt_clean)
mean_ln_alt <- mean(ln_alt_clean)# Calculate mean
sd_ln_alt <- sd(ln_alt_clean)# Calculate standard deviation

cat("Print: range of ln ALT=", min_ln_alt,max_ln_alt, "\n")
cat("Print: mean and SD of ln ALT=", mean_ln_alt," and ", sd_ln_alt, "\n")

plotNormalHistogram(ln_alt_clean, # Plot histogram with normal distribution line
                    prob = FALSE, 
                    col = "white", 
                    border = "black", 
                    main = "Distribution of natural log ALT(u/l)",
                    xlab = "Natural log of ALT(u/l)",
                    ylab = "Number of samples",
                    linecol = "red", 
                    lwd = 3)

density_data <- density(ln_alt_clean)# Calculate density

hist_data <- hist(ln_alt_clean, plot = FALSE) # Create the histogram to get the breaks for scaling the density

density_scaled <- density_data$y * diff(hist_data$mids[1:2]) * length(ln_alt_clean) # Scale density values to match the histogram frequency

# Add density lines
lines(density_data$x, density_scaled, col = "blue", lwd = 2)

# Add legend
legend("topright", 
       legend = c("Normal Distribution", "Density"), 
       col = c("red", "blue"), 
       lwd = 3, 
       cex = 0.8, 
       bty = "n")


#2. AST
num_na_ast <- sum(is.na(data$ast_u_l))
cat("Print: the number of NA in AST=", num_na_ast)
cat("Print: percentage of NA in AST=", (num_na_ast/dim(data)[1])*100)

# 2-1. check the distribution of ast
ast_clean <- na.omit(data$ast_u_l) # Remove missing values

min_ast <- min(ast_clean)# Calculate range
max_ast <- max(ast_clean)
mean_ast <- mean(ast_clean)# Calculate mean
sd_ast <- sd(ast_clean)# Calculate standard deviation

cat("Print: range of AST=", min_ast," and ", max_ast, "\n")
cat("Print: mean and SD of AST=", mean_ast," and ", sd_ast, "\n")


# Redraw the plot with extended axis limits
plotNormalHistogram(ast_clean, 
                    prob = FALSE, 
                    col = "white", 
                    border = "black", 
                    main = "Distribution of AST(u/l)",
                    xlab = "AST(u/l)",
                    ylab = "Number of samples",
                    linecol = "red", 
                    lwd = 3
                    )
              
density_data <- density(ast_clean)# Calculate density

hist_data <- hist(ast_clean, plot = FALSE) # Create the histogram to get the breaks for scaling the density

density_scaled <- density_data$y * diff(hist_data$mids[1:2]) * length(ast_clean) # Scale density values to match the histogram frequency

# Add density lines
lines(density_data$x, density_scaled, col = "blue", lwd = 2)

# Add legend
legend("topright", 
       legend = c("Normal Distribution", "Density"), 
       col = c("red", "blue"), 
       lwd = 3, 
       cex = 0.8, 
       bty = "n")

# 2-2. check the distribution of ln(ast), based on the distribution of ast, which needs natural log transformation.

num_na_ln_ast <- sum(is.na(data$log_ast)) #check the na
cat("Print: the number of NA in Ln AST=", num_na_ln_ast, "\n")
cat("Print: percentage of NA in Ln AST=", (num_na_ln_ast/dim(data)[1])*100,"\n")

ln_ast_clean <- na.omit(data$log_ast) # Remove missing values

min_ln_ast <- min(ln_ast_clean)# Calculate range
max_ln_ast <- max(ln_ast_clean)
mean_ln_ast <- mean(ln_ast_clean)# Calculate mean
sd_ln_ast <- sd(ln_ast_clean)# Calculate standard deviation

cat("Print: range of ln AST=", min_ln_ast," and ", max_ln_ast, "\n")
cat("Print: mean and SD of ln AST=", mean_ln_ast," and ", sd_ln_ast, "\n")

plotNormalHistogram(ln_ast_clean, # Plot histogram with normal distribution line
                    prob = FALSE, 
                    col = "white", 
                    border = "black", 
                    main = "Distribution of natural log AST(u/l)",
                    xlab = "Natural log of AST(u/l)",
                    ylab = "Number of samples",
                    linecol = "red", 
                    lwd = 3)

density_data <- density(ln_ast_clean)# Calculate density

hist_data <- hist(ln_ast_clean, plot = FALSE) # Create the histogram to get the breaks for scaling the density

density_scaled <- density_data$y * diff(hist_data$mids[1:2]) * length(ln_ast_clean) # Scale density values to match the histogram frequency

# Add density lines
lines(density_data$x, density_scaled, col = "blue", lwd = 2)

# Add legend
legend("topright", 
       legend = c("Normal Distribution", "Density"), 
       col = c("red", "blue"), 
       lwd = 3, 
       cex = 0.8, 
       bty = "n")


#3. AST/ALT ratio
num_na_ast_alt_ratio <- sum(is.na(data$`AST/ALT`))
cat("Print: the number of NA in AST/ALT ratio=", num_na_ast_alt_ratio)
cat("Print: percentage of NA in AST/ALT ratio=", (num_na_ast_alt_ratio/dim(data)[1])*100)

#3-1. check the distribution of ast
ast_alt_clean <- na.omit(data$`AST/ALT`) # Remove missing values

min_ast_alt <- min(ast_alt_clean)# Calculate range
max_ast_alt <- max(ast_alt_clean)
mean_ast_alt <- mean(ast_alt_clean)# Calculate mean
sd_ast_alt <- sd(ast_alt_clean)# Calculate standard deviation

cat("Print: range of AST/ALT ratio=", min_ast_alt," and ", max_ast_alt, "\n")
cat("Print: mean and SD of AST/ALT ratio=", mean_ast_alt," and ", sd_ast_alt, "\n")

# Redraw the plot with extended axis limits
plotNormalHistogram(ast_alt_clean, 
                    prob = FALSE, 
                    col = "white", 
                    border = "black", 
                    main = "Distribution of AST/ALT ratio",
                    xlab = "AST/ALT ratio",
                    ylab = "Number of samples",
                    linecol = "red", 
                    lwd = 3
                    )
              
density_data <- density(ast_alt_clean)# Calculate density

hist_data <- hist(ast_alt_clean, plot = FALSE) # Create the histogram to get the breaks for scaling the density

density_scaled <- density_data$y * diff(hist_data$mids[1:2]) * length(ast_alt_clean) # Scale density values to match the histogram frequency

# Add density lines
lines(density_data$x, density_scaled, col = "blue", lwd = 2)

# Add legend
legend("topright", 
       legend = c("Normal Distribution", "Density"), 
       col = c("red", "blue"), 
       lwd = 3, 
       cex = 0.8, 
       bty = "n")


# 3-2. check the distribution of ln(ast/alt), based on the distribution of ast/alt ratio, which needs natural log transformation.
num_na_ln_ast_alt <- sum(is.na(data$log_ast_alt)) #check the na
cat("Print: the number of NA in Ln AST/ALT=", num_na_ln_ast_alt, "\n")
cat("Print: percentage of NA in Ln AST/ALT=", (num_na_ln_ast_alt/dim(data)[1])*100,"\n")

ln_ast_alt_clean <- na.omit(data$log_ast_alt) # Remove missing values

min_ln_ast_alt <- min(ln_ast_alt_clean)# Calculate range
max_ln_ast_alt <- max(ln_ast_alt_clean)
mean_ln_ast_alt <- mean(ln_ast_alt_clean)# Calculate mean
sd_ln_ast_alt <- sd(ln_ast_alt_clean)# Calculate standard deviation

cat("Print: range of ln AST/ALT=", min_ln_ast,max_ln_ast_alt, "\n")
cat("Print: mean and SD of ln AST/ALT=", mean_ln_ast," and ", sd_ln_ast_alt, "\n")

plotNormalHistogram(ln_ast_alt_clean, # Plot histogram with normal distribution line
                    prob = FALSE, 
                    col = "white", 
                    border = "black", 
                    main = "Distribution of natural log AST/ALT ratio",
                    xlab = "Natural log of AST/ALT ratio",
                    ylab = "Number of samples",
                    linecol = "red", 
                    lwd = 3)

density_data <- density(ln_ast_alt_clean)# Calculate density

hist_data <- hist(ln_ast_alt_clean, plot = FALSE) # Create the histogram to get the breaks for scaling the density

density_scaled <- density_data$y * diff(hist_data$mids[1:2]) * length(ln_ast_alt_clean) # Scale density values to match the histogram frequency

# Add density lines
lines(density_data$x, density_scaled, col = "blue", lwd = 2)

# Add legend
legend("topright", 
       legend = c("Normal Distribution", "Density"), 
       col = c("red", "blue"), 
       lwd = 3, 
       cex = 0.8, 
       bty = "n")


# 4. correlation between natural ln ast, ln alt, and ln ast/alt ratio by sex

# 4-1. version 1
data_renamed <- data[, c('log_ast_alt', 'log_ast', 'log_alt', 'sex')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'sex')

custom_plot <- function(data, mapping, ...) {#Define the custom plot function for the lower panel
  ggplot(data, mapping) +
    geom_point(aes(color = sex), ...) +
    geom_smooth(aes(color = sex), method = "lm", se = FALSE, ...) # Separate regression lines by sex
}
p <- ggpairs(data_renamed,# Generate the ggpairs plot with the custom plot function
             columns = 1:3,  # Only use the numeric columns for the pairs plot
             aes(color = sex),  # Color points by sex
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()
print(p)

#4-2. version2
custom_plot <- function(data, mapping, ...) {
  ggplot(data, mapping) +
    geom_point(aes(color = sex), ...) +
    geom_smooth(aes(color = sex), method = "lm", se = FALSE, ...)
}
p <- ggpairs(data_renamed, 
             aes(color = sex),
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()

for(i in 1:p$nrow) {# Customize color scales manually
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
      scale_fill_manual(values=c("#00AFBB",  "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#FC4E07"))  
  }
}
print(p)


# 5. correlation between natural ln ast, ln alt, and ln ast/alt ratio by categorical endpoints

# 5-1. AST cat1: cutoff 29 for Male and 19 for female
data_renamed <- data[, c('log_ast_alt', 'log_ast', 'log_alt', 'ast_cat1')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'lowest cut AST')

custom_plot <- function(data, mapping, ...) {
  ggplot(data, mapping) +
    geom_point(aes(color = `lowest cut AST`), ...) +
    geom_smooth(aes(color = `lowest cut AST`), method = "lm", se = FALSE, ...)
}
p1 <- ggpairs(data_renamed, 
             aes(color = `lowest cut AST`),
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()

for(i in 1:p$nrow) {# Customize color scales manually
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
      scale_fill_manual(values=c("#00AFBB", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#FC4E07"))  
  }
}
print(p1)

# 5-2. AST cat2: cutoff 33 for Male and 25 for female
data_renamed <- data[, c('log_ast_alt', 'log_ast', 'log_alt', 'ast_cat2')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'highest cut AST')

custom_plot <- function(data, mapping, ...) {
  ggplot(data, mapping) +
    geom_point(aes(color = `highest cut AST`), ...) +
    geom_smooth(aes(color = `highest cut AST`), method = "lm", se = FALSE, ...)
}
p2 <- ggpairs(data_renamed, 
             aes(color = `highest cut AST`),
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()

for(i in 1:p$nrow) {# Customize color scales manually
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
      scale_fill_manual(values=c("#00AFBB", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#FC4E07"))  
  }
}
print(p2)

# 5-3. ALT cat1: cutoff 29 for Male and 19 for female
data_renamed <- data[, c('log_ast_alt', 'log_ast', 'log_alt', 'alt_cat1')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'lowest cut ALT')

custom_plot <- function(data, mapping, ...) {
  ggplot(data, mapping) +
    geom_point(aes(color = `lowest cut ALT`), ...) +
    geom_smooth(aes(color = `lowest cut ALT`), method = "lm", se = FALSE, ...)
}
p3 <- ggpairs(data_renamed, 
             aes(color = `lowest cut ALT`),
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()

for(i in 1:p$nrow) {# Customize color scales manually
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
      scale_fill_manual(values=c("#00AFBB", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#FC4E07"))  
  }
}
print(p3)

# 5-4. ALT cat2: cutoff 33 for Male and 25 for female
data_renamed <- data[, c('log_ast_alt', 'log_ast', 'log_alt', 'alt_cat2')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'highest cut ALT')

custom_plot <- function(data, mapping, ...) {
  ggplot(data, mapping) +
    geom_point(aes(color = `highest cut ALT`), ...) +
    geom_smooth(aes(color = `highest cut ALT`), method = "lm", se = FALSE, ...)
}
p4 <- ggpairs(data_renamed, 
             aes(color = `highest cut ALT`),
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()

for(i in 1:p$nrow) {# Customize color scales manually
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
      scale_fill_manual(values=c("#00AFBB", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#FC4E07"))  
  }
}
print(p4)

# 5-5. cirrhosis
data_renamed <- data[, c('log_ast_alt', 'log_ast', 'log_alt', 'cirrhosis')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'cirrhosis')

custom_plot <- function(data, mapping, ...) {
  ggplot(data, mapping) +
    geom_point(aes(color = `cirrhosis`), ...) +
    geom_smooth(aes(color = `cirrhosis`), method = "lm", se = FALSE, ...)
}

p5 <- ggpairs(data_renamed, 
             aes(color = `cirrhosis`),
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()

for(i in 1:p$nrow) {# Customize color scales manually
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
      scale_fill_manual(values=c("#00AFBB", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#FC4E07"))  
  }
}
print(p5)

# 5-6. case_control

# 5-6-1. Total ppl
data_renamed <- data[, c('log_ast_alt', 'log_ast', 'log_alt', 'case_control')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'Cirrhosis diagnosed')

custom_plot <- function(data, mapping, ...) {
  ggplot(data, mapping) +
    geom_point(aes(color = `Cirrhosis diagnosed`), ...) +
    geom_smooth(aes(color = `Cirrhosis diagnosed`), method = "lm", se = FALSE, ...)
}

p6 <- ggpairs(data_renamed, 
             aes(color = `Cirrhosis diagnosed`),
             lower = list(continuous = custom_plot),
             upper = list(continuous = wrap("cor", size = 4))) +
  theme_bw()

for(i in 1:p$nrow) {# Customize color scales manually
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + 
      scale_fill_manual(values=c("#00AFBB", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#FC4E07"))  
  }
}
print(p6)

# 5-6-2. After excluding NCSU data
# Before analyzing this, subsetting excluding NCSU data (182 ppl, 48.1%)
#(dim(data[data$source=='NCSU',])[1]/dim(data)[1])*100
data_ex_ncsu <- data[data$source=='NCSU',]

data_renamed <- data_ex_ncsu[, c('log_ast_alt', 'log_ast', 'log_alt', 'case_control')]
colnames(data_renamed) <- c('natural log AST/ALT', 'natural log AST', 'natural log ALT', 'Cirrhosis diagnosed')

# 6. A frequency table of categorical outcomes

# 6-1. Total ppl
data_renamed <- data[, c('ast_cat1', 'ast_cat2', 'alt_cat1','alt_cat2', 'cirrhosis','case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis','cirrhosis diagnosed')

data_renamed$cirrhosis <- factor(data_renamed$cirrhosis,
                                 levels = c("Healthy", "Cirrhosis"),
                                 labels = c("Normal", "Abnormal"))

data_renamed$`cirrhosis diagnosed` <- factor(data_renamed$`cirrhosis diagnosed`,
                                             levels = c("Healthy", "Cirrhosis"),
                                             labels = c("Normal", "Abnormal"))


frequency_tables <- lapply(data_renamed, function(x) {
  tbl <- as.data.frame(table(x))
  colnames(tbl) <- c("Category", "Frequency")
  return(tbl)
})

combined_freq_df <- bind_rows(lapply(names(frequency_tables), function(name) {
  df <- frequency_tables[[name]]
  df$Variable <- name
  return(df)
}))

combined_freq_df <- combined_freq_df %>%
  pivot_wider(names_from = Variable, values_from = Frequency, values_fill = list(Frequency = 0)) %>%
  arrange(Category)

combined_freq_df <- combined_freq_df %>%
  dplyr::select(Category, everything())

combined_freq_df$Category <- as.character(combined_freq_df$Category)

total_row <- colSums(combined_freq_df[,-1])
total_row <- c("Total", total_row)

combined_freq_df <- rbind(combined_freq_df, total_row)

fancy_table1 <- flextable(combined_freq_df)
fancy_table1 <- set_table_properties(fancy_table1, width = 0.8, layout = "autofit")

fancy_table1 <- set_caption(fancy_table1, caption = "Frequency tables for categorical endpoints in total ppl (N=349)")

fancy_table1 <- fontsize(fancy_table1, size = 8, part = "body") # Reduce font size of values
fancy_table1 <- fontsize(fancy_table1, size = 9, part = "header") # Reduce font size of header
fancy_table1 <- border(fancy_table1, i = (nrow(fancy_table1$body$dataset)-1), border.bottom = fp_border(color = "black"))
fancy_table1 <- align(fancy_table1, align = "center", part = "body")

print(fancy_table1)

# 6-2. After excluding Total ppl
data_renamed <- data_ex_ncsu[, c('ast_cat1', 'ast_cat2', 'alt_cat1','alt_cat2', 'cirrhosis','case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis','cirrhosis diagnosed')

data_renamed$cirrhosis <- factor(data_renamed$cirrhosis,
                                 levels = c("Healthy", "Cirrhosis"),
                                 labels = c("Normal", "Abnormal"))

data_renamed$`cirrhosis diagnosed` <- factor(data_renamed$`cirrhosis diagnosed`,
                                             levels = c("Healthy", "Cirrhosis"),
                                             labels = c("Normal", "Abnormal"))


frequency_tables <- lapply(data_renamed, function(x) {
  tbl <- as.data.frame(table(x))
  colnames(tbl) <- c("Category", "Frequency")
  return(tbl)
})

combined_freq_df <- bind_rows(lapply(names(frequency_tables), function(name) {
  df <- frequency_tables[[name]]
  df$Variable <- name
  return(df)
}))

combined_freq_df <- combined_freq_df %>%
  pivot_wider(names_from = Variable, values_from = Frequency, values_fill = list(Frequency = 0)) %>%
  arrange(Category)

combined_freq_df <- combined_freq_df %>%
  dplyr::select(Category, everything())

combined_freq_df$Category <- as.character(combined_freq_df$Category)

total_row <- colSums(combined_freq_df[,-1])
total_row <- c("Total", total_row)

combined_freq_df <- rbind(combined_freq_df, total_row)

fancy_table2 <- flextable(combined_freq_df)
fancy_table2 <- set_table_properties(fancy_table2, width = 0.8, layout = "autofit")

fancy_table2 <- set_caption(fancy_table2, caption = "Frequency tables for categorical endpoints after exlcuding NCSU (N=173)")

fancy_table2 <- fontsize(fancy_table2, size = 8, part = "body") # Reduce font size of values
fancy_table2 <- fontsize(fancy_table2, size = 9, part = "header") # Reduce font size of header
fancy_table2 <- border(fancy_table2, i = (nrow(fancy_table2$body$dataset)-1), border.bottom = fp_border(color = "black"))
fancy_table2 <- align(fancy_table2, align = "center", part = "body")

print(fancy_table2)

# Create a new Word document
doc <- read_docx()

# Add the first flextable
doc <- body_add_flextable(doc, value = fancy_table1)

# Add a page break (optional) or additional spacing
doc <- body_add_par(doc, value = " ", style = "Normal")
doc <- body_add_par(doc, value = " ", style = "Normal")

# Add the second flextable
doc <- body_add_flextable(doc, value = fancy_table2)

# Save the document
print(doc, target = "Frequency tables of categorical outcome vars.docx")

# 7. Association between cat endpoints 
# 7-1 through correlation matrix
# 7-1-1. total ppl
data_renamed <- data[, c('ast_cat1', 'ast_cat2', 'alt_cat1','alt_cat2', 'cirrhosis','case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis','cirrhosis diagnosed')

# Relabel the 'cirrhosis' variables
data_renamed$cirrhosis <- factor(data_renamed$cirrhosis,
                                 levels = c("Healthy", "Cirrhosis"),
                                 labels = c("Normal", "Abnormal"))

data_renamed$`cirrhosis diagnosed` <- factor(data_renamed$`cirrhosis diagnosed`,
                                 levels = c("Healthy", "Cirrhosis"),
                                 labels = c("Normal", "Abnormal"))

# Create dummy variables and compute correlation matrix
correlation_matrix <- model.matrix(~0 + ., data=data_renamed) %>% 
     cor(use="pairwise.complete.obs")



# Plot the correlation matrix using ggcorrplot
plot6 <-ggcorrplot(correlation_matrix, 
           show.diag=FALSE, 
           type="lower", 
           lab=TRUE, 
           lab_size=2,
           title="Correlation matrix of categorical outcomes in total ppl (N=349)") +  # Title of the plot
        theme(
          plot.title = element_text(size = 10), # Title font size
          axis.text.x = element_text(size = 8), # X-axis title font size
          axis.text.y = element_text(size = 8)  # Y-axis title font size
        )

print(plot6)



# 7-1-2. after excluding NCSU data
data_renamed <- data_ex_ncsu[, c('ast_cat1', 'ast_cat2', 'alt_cat1','alt_cat2', 'cirrhosis','case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis','cirrhosis diagnosed')

# Relabel the 'cirrhosis' variables
data_renamed$cirrhosis <- factor(data_renamed$cirrhosis,
                                 levels = c("Healthy", "Cirrhosis"),
                                 labels = c("Normal", "Abnormal"))

data_renamed$`cirrhosis diagnosed` <- factor(data_renamed$`cirrhosis diagnosed`,
                                 levels = c("Healthy", "Cirrhosis"),
                                 labels = c("Normal", "Abnormal"))

# Create dummy variables and compute correlation matrix
correlation_matrix <- model.matrix(~0 + ., data=data_renamed) %>% 
     cor(use="pairwise.complete.obs")


# Plot the correlation matrix using ggcorrplot
plot6 <-ggcorrplot(correlation_matrix, 
           show.diag=FALSE, 
           type="lower", 
           lab=TRUE, 
           lab_size=2,
           title="Correlation matrix of categorical outcomes after excluding NCSU data (N=173)") +  # Title of the plot
        theme(
          plot.title = element_text(size = 10), # Title font size
          axis.text.x = element_text(size = 8), # X-axis title font size
          axis.text.y = element_text(size = 8)  # Y-axis title font size
        )

print(plot6)

###########Tabulate

# 1. total ppl
# Create dummy variables
data_renamed <- data[, c('ast_cat1', 'ast_cat2', 'alt_cat1','alt_cat2', 'cirrhosis','case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis','cirrhosis diagnosed')

model_matrix <- model.matrix(~0 + ., data = data_renamed)
correlation_matrix <- cor(model_matrix, use = "pairwise.complete.obs")

# Function to calculate p-values for correlations
cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat <- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], ...)
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# Calculate p-values
p.mat <- cor.mtest(model_matrix)

# Convert correlation matrix and p-value matrix to long format
cor_long <- melt(correlation_matrix)
pval_long <- melt(p.mat)

# Rename columns for merging
colnames(cor_long) <- c("Var1", "Var2", "correlation")
colnames(pval_long) <- c("Var1", "Var2", "pvalue")

# Merge correlation and p-value data frames
plot_df <- merge(cor_long, pval_long, by = c("Var1", "Var2"))

# Check the structure and content of the merged data frame
print("Structure of plot_df:")
str(plot_df)
print("First few rows of plot_df:")
head(plot_df)

# Remove duplicate comparisons (keep only one direction)
plot_df <- plot_df %>%
  mutate(Var1 = as.character(Var1), Var2 = as.character(Var2)) %>%
  arrange(Var1, Var2) %>%
  distinct(Var1, Var2, .keep_all = TRUE) %>%
  filter(Var1 < Var2)  # Keep only one direction of the comparison

# Ensure pvalue is numeric for formatting
plot_df <- plot_df %>%
  mutate(pvalue = as.numeric(pvalue)) %>%
  mutate(pvalue = ifelse(pvalue < 0.001, "<0.001", sprintf("%.3f", pvalue)),
         correlation = sprintf("%.3f", correlation))

# Check the updated plot_df
print("Structure of updated plot_df:")
str(plot_df)
print("First few rows of updated plot_df:")
head(plot_df)

ft <- flextable(plot_df)

ft <- set_table_properties(ft, width = 0.75, layout = "autofit") %>%
      set_header_labels(values = c(Var1 = "Cat Endpoint 1", Var2 = "Cat Endpoint 2", correlation = "Correlation", pvalue = "P")) %>%
      color(color = "#000000") %>%
      fontsize(size = 9) 
# Add caption 
ft <- set_caption(ft, caption = "Inter-correlation table of categorical endpoints in total ppl (N=349)")

print(ft)     

# 2. after excluding NCSU data
data_renamed <- data_ex_ncsu[, c('ast_cat1', 'ast_cat2', 'alt_cat1','alt_cat2', 'cirrhosis','case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis','cirrhosis diagnosed')

model_matrix <- model.matrix(~0 + ., data = data_renamed)
correlation_matrix <- cor(model_matrix, use = "pairwise.complete.obs")

cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat <- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], ...)
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

p.mat <- cor.mtest(model_matrix)

cor_long <- melt(correlation_matrix)
pval_long <- melt(p.mat)

colnames(cor_long) <- c("Var1", "Var2", "correlation")
colnames(pval_long) <- c("Var1", "Var2", "pvalue")

plot_df <- merge(cor_long, pval_long, by = c("Var1", "Var2"))

print("Structure of plot_df:")
str(plot_df)
print("First few rows of plot_df:")
head(plot_df)

plot_df <- plot_df %>%
  mutate(Var1 = as.character(Var1), Var2 = as.character(Var2)) %>%
  arrange(Var1, Var2) %>%
  distinct(Var1, Var2, .keep_all = TRUE) %>%
  filter(Var1 < Var2)  # Keep only one direction of the comparison

# Ensure pvalue is numeric for formatting
plot_df <- plot_df %>%
  mutate(pvalue = as.numeric(pvalue)) %>%
  mutate(pvalue = ifelse(pvalue < 0.001, "<0.001", sprintf("%.3f", pvalue)),
         correlation = sprintf("%.3f", correlation))

print("Structure of updated plot_df:")
str(plot_df)
print("First few rows of updated plot_df:")
head(plot_df)

ft1 <- flextable(plot_df)

ft1 <- set_table_properties(ft1, width = 0.75, layout = "autofit") %>%
      set_header_labels(values = c(Var1 = "Cat Endpoint 1", Var2 = "Cat Endpoint 2", correlation = "Correlation", pvalue = "P")) %>%
      color(color = "#000000") %>%
      fontsize(size = 9) 
# Add caption 
ft1 <- set_caption(ft1, caption = "Inter-correlation table of categorical endpoints after excluding NCSU data (N=173)")

print(ft1)     

#save
doc <- read_docx()
doc <- body_add_flextable(doc, ft)

doc <- body_add_par(doc, value = " ", style = "Normal")
doc <- body_add_par(doc, value = " ", style = "Normal")
doc <- body_add_flextable(doc, ft1)

print(doc, target = "Correlation of intercategorical endpoints.docx")
```

# Diagnosis of categorical endpoints 
```{r}
#1. endpoint diagnosis
results <- list()

data_renamed <- data[, c('ast_cat1', 'ast_cat2', 'alt_cat1', 'alt_cat2', 'cirrhosis', 'case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis', 'cirrhosis diagnosed')

data_renamed$cirrhosis <- factor(data_renamed$cirrhosis, levels = c("Cirrhosis", "Healthy"), labels = c("Abnormal", "Normal"))
data_renamed$`cirrhosis diagnosed` <- factor(data_renamed$`cirrhosis diagnosed`, levels = c("Cirrhosis", "Healthy"), labels = c("Abnormal", "Normal"))

variables <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis', 'cirrhosis diagnosed')

for (i in seq_along(variables)) {
  for (j in seq_along(variables)) {
    if (i != j) {
      # Ensure both variables have the same length and no NAs
      if (length(data_renamed[[variables[i]]]) == length(data_renamed[[variables[j]]])) {
        
        # Remove rows with NA values in either variable
        valid_indices <- complete.cases(data_renamed[[variables[i]]], data_renamed[[variables[j]]])
        valid_data_i <- data_renamed[[variables[i]]][valid_indices]
        valid_data_j <- data_renamed[[variables[j]]][valid_indices]
        
        # Print data for debugging
        print(paste("Data for", variables[i], "vs", variables[j]))
        print(head(valid_data_i))
        print(head(valid_data_j))
        
        # Generate confusion matrix
        conf_matrix <- table(predicted = valid_data_i, actual = valid_data_j)
        
        # Print confusion matrix for debugging
        print(paste("Confusion Matrix for", variables[i], "vs", variables[j]))
        print(conf_matrix)
        
        # Get levels from confusion matrix
        levels_i <- rownames(conf_matrix)
        levels_j <- colnames(conf_matrix)
        
        # Initialize metric values
        sensitivity <- specificity <- ppv <- npv <- accuracy <- auc_value <- f1_score <- kappa_value <- NA
        
        # Check if both 'Abnormal/cirrhosis' and 'Normal' are present in confusion matrix
        if ("Abnormal" %in% levels_i && "Abnormal" %in% levels_j &&
            "Normal" %in% levels_i && "Normal" %in% levels_j) {
          
          # Extract values safely
          true_pos <- conf_matrix["Abnormal", "Abnormal"] %>% ifelse(is.na(.), 0, .)
          false_neg <- conf_matrix["Abnormal", "Normal"] %>% ifelse(is.na(.), 0, .)
          false_pos <- conf_matrix["Normal", "Abnormal"] %>% ifelse(is.na(.), 0, .)
          true_neg <- conf_matrix["Normal", "Normal"] %>% ifelse(is.na(.), 0, .)
          
          # Calculate metrics
          sensitivity <- true_pos / (true_pos + false_neg)
          specificity <- true_neg / (true_neg + false_pos)
          ppv <- true_pos / (true_pos + false_pos)
          npv <- true_neg / (true_neg + false_neg)
          accuracy <- (true_pos + true_neg) / sum(conf_matrix)
          
          # Ensure valid_data_i is numeric and valid_data_j is a factor
          valid_data_i_numeric <- as.numeric(factor(valid_data_i, levels = unique(valid_data_i)))
          valid_data_j_factor <- factor(valid_data_j, levels = c("Normal", "Abnormal")) # Assuming "High" is positive class
          
          # Print data for ROC debugging
          print("Valid Data for ROC")
          print(head(valid_data_i_numeric))
          print(head(valid_data_j_factor))
          
          # ROC Curve and AUC
          roc_curve <- tryCatch({
            roc(valid_data_j_factor, valid_data_i_numeric)
          }, error = function(e) {
            print("Error in ROC calculation")
            return(NULL)
          })
          
          auc_value <- if (!is.null(roc_curve)) auc(roc_curve) else NA
          
          # F1 Score
          f1_score <- if (!is.na(ppv + sensitivity) && ppv + sensitivity > 0) {
            2 * (ppv * sensitivity) / (ppv + sensitivity)
          } else {
            NA
          }
          
          # Kappa Statistic
          kappa_value <- tryCatch({
            kappa2(conf_matrix)$value
          }, error = function(e) {
            print("Error in Kappa calculation")
            return(NA)
          })
        }
        
        # Store results
        results[[paste(variables[i], "vs", variables[j])]] <- c(
          Sensitivity = sensitivity,
          Specificity = specificity,
          PPV = ppv,
          NPV = npv,
          Accuracy = accuracy,
          AUC = auc_value,
          F1_Score = f1_score,
          Kappa = kappa_value
        )
      } else {
        results[[paste(variables[i], "vs", variables[j])]] <- c(
          Sensitivity = NA,
          Specificity = NA,
          PPV = NA,
          NPV = NA,
          Accuracy = NA,
          AUC = NA,
          F1_Score = NA,
          Kappa = NA
        )
      }
    }
  }
}

results_df <- do.call(rbind, results)
results_df <- as.data.frame(results_df)

results_df <- results_df %>% dplyr::select(-AUC)

results_df <- results_df %>%
  mutate(across(everything(), ~ case_when(
    . == 1.000 ~ "1",
    . == 0.000 ~ "0",
    TRUE ~ sprintf("%.3f", .)
  )))


results_df$Comparison <- rownames(results_df)

results_df <- results_df %>% dplyr::select(Comparison, everything())

fancy_table <- flextable(results_df)
fancy_table <- set_table_properties(fancy_table, width = 0.8, layout = "autofit")

fancy_table <- set_caption(fancy_table, caption = "Confusion matrix results table (N=349)")

fancy_table <- fontsize(fancy_table, size = 8, part = "all") # Reduce font size of values
fancy_table <- fontsize(fancy_table, size = 9, part = "header") # Reduce font size of header

print(fancy_table)

#2. setting case_control as gold standard in total ppl
results <- list()
seen_comparisons <- character()  # Initialize seen_comparisons as a character vector

data_renamed <- data[, c('ast_cat1', 'ast_cat2', 'alt_cat1', 'alt_cat2', 'cirrhosis', 'case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis', 'cirrhosis diagnosed')

data_renamed$cirrhosis <- factor(data_renamed$cirrhosis, levels = c("Cirrhosis", "Healthy"), labels = c("Abnormal", "Normal"))
data_renamed$`cirrhosis diagnosed` <- factor(data_renamed$`cirrhosis diagnosed`, levels = c("Cirrhosis", "Healthy"), labels = c("Abnormal", "Normal"))

variables <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis', 'cirrhosis diagnosed')

# Identify the gold standard variable
gold_standard <- 'cirrhosis diagnosed'

for (i in seq_along(variables)) {
  for (j in seq_along(variables)) {
    if (i != j) {
      # Define the comparison names
      comparison_name_1 <- paste(variables[i], "vs", variables[j])
      comparison_name_2 <- paste(variables[j], "vs", variables[i])
      
      # Skip if the reverse comparison has already been processed
      if (comparison_name_2 %in% seen_comparisons) {
        next
      }
      
      # Mark the first comparison as seen
      seen_comparisons <- c(seen_comparisons, comparison_name_1)
      
      # Ensure both variables have the same length and no NAs
      if (length(data_renamed[[variables[i]]]) == length(data_renamed[[variables[j]]])) {
        
        # Remove rows with NA values in either variable
        valid_indices <- complete.cases(data_renamed[[variables[i]]], data_renamed[[variables[j]]])
        valid_data_i <- data_renamed[[variables[i]]][valid_indices]
        valid_data_j <- data_renamed[[variables[j]]][valid_indices]
        
        # Check if gold standard is involved
        if (variables[j] == gold_standard) {
          predicted <- valid_data_i
          actual <- valid_data_j
        } else if (variables[i] == gold_standard) {
          predicted <- valid_data_j
          actual <- valid_data_i
        } else {
          next
        }
        
        # Generate confusion matrix
        conf_matrix <- table(predicted = predicted, actual = actual)
        
        # Print confusion matrix for debugging
        print(paste("Confusion Matrix for", comparison_name_1))
        print(conf_matrix)
        
        # Check for at least one Abnormal and one Normal class in both predicted and actual
        levels_i <- rownames(conf_matrix)
        levels_j <- colnames(conf_matrix)
        
        if ("Abnormal" %in% levels_i && "Abnormal" %in% levels_j &&
            "Normal" %in% levels_i && "Normal" %in% levels_j) {
          
          # Extract values safely
          true_pos <- conf_matrix["Abnormal", "Abnormal"] %>% ifelse(is.na(.), 0, .)
          false_neg <- conf_matrix["Abnormal", "Normal"] %>% ifelse(is.na(.), 0, .)
          false_pos <- conf_matrix["Normal", "Abnormal"] %>% ifelse(is.na(.), 0, .)
          true_neg <- conf_matrix["Normal", "Normal"] %>% ifelse(is.na(.), 0, .)
          
          # Calculate metrics
          sensitivity <- true_pos / (true_pos + false_neg)
          specificity <- true_neg / (true_neg + false_pos)
          ppv <- true_pos / (true_pos + false_pos)
          npv <- true_neg / (true_neg + false_neg)
          accuracy <- (true_pos + true_neg) / sum(conf_matrix)
          
          # Ensure predicted is numeric and actual is a factor
          predicted_numeric <- as.numeric(factor(predicted, levels = unique(predicted)))
          actual_factor <- factor(actual, levels = c("Normal", "Abnormal")) # Assuming "Abnormal" is positive class
          
          # ROC Curve and AUC
          roc_curve <- tryCatch({
            roc(actual_factor, predicted_numeric)
          }, error = function(e) {
            print("Error in ROC calculation")
            return(NULL)
          })
          
          auc_value <- if (!is.null(roc_curve)) auc(roc_curve) else NA
          
          # F1 Score
          f1_score <- if (!is.na(ppv + sensitivity) && ppv + sensitivity > 0) {
            2 * (ppv * sensitivity) / (ppv + sensitivity)
          } else {
            NA
          }
          
          # Kappa Statistic
          kappa_value <- tryCatch({
            kappa2(conf_matrix)$value
          }, error = function(e) {
            print("Error in Kappa calculation")
            return(NA)
          })
          
          # Store results
          results[[comparison_name_1]] <- c(
            Sensitivity = sensitivity,
            Specificity = specificity,
            PPV = ppv,
            NPV = npv,
            Accuracy = accuracy,
            AUC = auc_value,
            F1_Score = f1_score,
            Kappa = kappa_value
          )
        } else {
          results[[comparison_name_1]] <- c(
            Sensitivity = NA,
            Specificity = NA,
            PPV = NA,
            NPV = NA,
            Accuracy = NA,
            AUC = NA,
            F1_Score = NA,
            Kappa = NA
          )
        }
      } else {
        results[[comparison_name_1]] <- c(
          Sensitivity = NA,
          Specificity = NA,
          PPV = NA,
          NPV = NA,
          Accuracy = NA,
          AUC = NA,
          F1_Score = NA,
          Kappa = NA
        )
      }
    }
  }
}

# Convert results to dataframe
results_df <- do.call(rbind, results)
results_df <- as.data.frame(results_df)

# Remove AUC column
results_df <- results_df %>% dplyr::select(-AUC)

# Format results
results_df <- results_df %>%
  mutate(across(everything(), ~ case_when(
    . == 1.000 ~ "1",
    . == 0.000 ~ "0",
    TRUE ~ sprintf("%.3f", .)
  )))

results_df$Comparison <- rownames(results_df)

# Reorder columns
results_df <- results_df %>% dplyr::select(Comparison, everything())

# Filter to keep only the first comparison result (ignoring reversed comparisons)
results_df <- results_df %>%
  filter(!grepl("vs", Comparison) | !duplicated(gsub("vs.*", "", Comparison)))

# Create flextable
fancy_table1 <- flextable(results_df)
fancy_table1 <- set_table_properties(fancy_table1, width = 0.8, layout = "autofit")

fancy_table1 <- set_caption(fancy_table1, caption = "Diagnosis of new categorical endpoints compared to case control status (gold standard) in total ppl (N=349)")

fancy_table1 <- fontsize(fancy_table1, size = 8, part = "all") # Reduce font size of values
fancy_table1 <- fontsize(fancy_table1, size = 9, part = "header") # Reduce font size of header

# Print flextable
print(fancy_table1)

############### scatter plot
results_df <- results_df %>% dplyr::select(-Kappa)

results_long <- results_df %>%
  pivot_longer(cols = -Comparison, names_to = "Metric", values_to = "Value")

results_long <- results_long %>%
  mutate(Value = as.numeric(Value)) %>%
  filter(!is.na(Value)) 

new_labels <- c(
  "cirrhosis vs cirrhosis diagnosed" = "cirrhosis by ast/alt>1",
  "highest cut alt vs cirrhosis diagnosed" = "highest cut alt",
  "lowest cut alt vs cirrhosis diagnosed" = "lowest cut alt",
  "highest cut ast vs cirrhosis diagnosed" = "highest cut ast",
  "lowest cut ast vs cirrhosis diagnosed" = "lowest cut ast"
)

palette_colors <- brewer.pal(n = length(unique(results_long$Comparison)), name = "Set1")  

# Recode the Comparison column
results_long <- results_long %>%
  mutate(Comparison = recode(Comparison, !!!new_labels))


# Create the scatter plot
ggplot(results_long, aes(x = Value, y = Metric, color = Comparison, shape = Comparison)) +
  geom_point(size = 3) +
  labs(title = "Diagnostic testing in total",
       x = "Scores",
       y = "Measure of diagnostic test performance",
       color = "Comparison",
       shape = "Comparison") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) + # Adjust x-axis
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.title = element_text(size = 12),
        legend.position = "right") +
  scale_shape_manual(values = 1:length(unique(results_long$Comparison))) +
  scale_color_manual(values = palette_colors)



# 3. after excluding NCSU data
results <- list()
seen_comparisons <- character()  # Initialize seen_comparisons as a character vector

data_renamed <- data_ex_ncsu[, c('ast_cat1', 'ast_cat2', 'alt_cat1', 'alt_cat2', 'cirrhosis', 'case_control')]
colnames(data_renamed) <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis', 'cirrhosis diagnosed')

data_renamed$cirrhosis <- factor(data_renamed$cirrhosis, levels = c("Cirrhosis", "Healthy"), labels = c("Abnormal", "Normal"))
data_renamed$`cirrhosis diagnosed` <- factor(data_renamed$`cirrhosis diagnosed`, levels = c("Cirrhosis", "Healthy"), labels = c("Abnormal", "Normal"))

variables <- c('lowest cut ast', 'highest cut ast', 'lowest cut alt', 'highest cut alt', 'cirrhosis', 'cirrhosis diagnosed')

# Identify the gold standard variable
gold_standard <- 'cirrhosis diagnosed'

for (i in seq_along(variables)) {
  for (j in seq_along(variables)) {
    if (i != j) {
      # Define the comparison names
      comparison_name_1 <- paste(variables[i], "vs", variables[j])
      comparison_name_2 <- paste(variables[j], "vs", variables[i])
      
      # Skip if the reverse comparison has already been processed
      if (comparison_name_2 %in% seen_comparisons) {
        next
      }
      
      # Mark the first comparison as seen
      seen_comparisons <- c(seen_comparisons, comparison_name_1)
      
      # Ensure both variables have the same length and no NAs
      if (length(data_renamed[[variables[i]]]) == length(data_renamed[[variables[j]]])) {
        
        # Remove rows with NA values in either variable
        valid_indices <- complete.cases(data_renamed[[variables[i]]], data_renamed[[variables[j]]])
        valid_data_i <- data_renamed[[variables[i]]][valid_indices]
        valid_data_j <- data_renamed[[variables[j]]][valid_indices]
        
        # Check if gold standard is involved
        if (variables[j] == gold_standard) {
          predicted <- valid_data_i
          actual <- valid_data_j
        } else if (variables[i] == gold_standard) {
          predicted <- valid_data_j
          actual <- valid_data_i
        } else {
          next
        }
        
        # Generate confusion matrix
        conf_matrix <- table(predicted = predicted, actual = actual)
        
        # Print confusion matrix for debugging
        print(paste("Confusion Matrix for", comparison_name_1))
        print(conf_matrix)
        
        # Check for at least one Abnormal and one Normal class in both predicted and actual
        levels_i <- rownames(conf_matrix)
        levels_j <- colnames(conf_matrix)
        
        if ("Abnormal" %in% levels_i && "Abnormal" %in% levels_j &&
            "Normal" %in% levels_i && "Normal" %in% levels_j) {
          
          # Extract values safely
          true_pos <- conf_matrix["Abnormal", "Abnormal"] %>% ifelse(is.na(.), 0, .)
          false_neg <- conf_matrix["Abnormal", "Normal"] %>% ifelse(is.na(.), 0, .)
          false_pos <- conf_matrix["Normal", "Abnormal"] %>% ifelse(is.na(.), 0, .)
          true_neg <- conf_matrix["Normal", "Normal"] %>% ifelse(is.na(.), 0, .)
          
          # Calculate metrics
          sensitivity <- true_pos / (true_pos + false_neg)
          specificity <- true_neg / (true_neg + false_pos)
          ppv <- true_pos / (true_pos + false_pos)
          npv <- true_neg / (true_neg + false_neg)
          accuracy <- (true_pos + true_neg) / sum(conf_matrix)
          
          # Ensure predicted is numeric and actual is a factor
          predicted_numeric <- as.numeric(factor(predicted, levels = unique(predicted)))
          actual_factor <- factor(actual, levels = c("Normal", "Abnormal")) # Assuming "Abnormal" is positive class
          
          # ROC Curve and AUC
          roc_curve <- tryCatch({
            roc(actual_factor, predicted_numeric)
          }, error = function(e) {
            print("Error in ROC calculation")
            return(NULL)
          })
          
          auc_value <- if (!is.null(roc_curve)) auc(roc_curve) else NA
          
          # F1 Score
          f1_score <- if (!is.na(ppv + sensitivity) && ppv + sensitivity > 0) {
            2 * (ppv * sensitivity) / (ppv + sensitivity)
          } else {
            NA
          }
          
          # Kappa Statistic
          kappa_value <- tryCatch({
            kappa2(conf_matrix)$value
          }, error = function(e) {
            print("Error in Kappa calculation")
            return(NA)
          })
          
          # Store results
          results[[comparison_name_1]] <- c(
            Sensitivity = sensitivity,
            Specificity = specificity,
            PPV = ppv,
            NPV = npv,
            Accuracy = accuracy,
            AUC = auc_value,
            F1_Score = f1_score,
            Kappa = kappa_value
          )
        } else {
          results[[comparison_name_1]] <- c(
            Sensitivity = NA,
            Specificity = NA,
            PPV = NA,
            NPV = NA,
            Accuracy = NA,
            AUC = NA,
            F1_Score = NA,
            Kappa = NA
          )
        }
      } else {
        results[[comparison_name_1]] <- c(
          Sensitivity = NA,
          Specificity = NA,
          PPV = NA,
          NPV = NA,
          Accuracy = NA,
          AUC = NA,
          F1_Score = NA,
          Kappa = NA
        )
      }
    }
  }
}

# Convert results to dataframe
results_df <- do.call(rbind, results)
results_df <- as.data.frame(results_df)

# Remove AUC column
results_df <- results_df %>% dplyr::select(-AUC)

# Format results
results_df <- results_df %>%
  mutate(across(everything(), ~ case_when(
    . == 1.000 ~ "1",
    . == 0.000 ~ "0",
    TRUE ~ sprintf("%.3f", .)
  )))

results_df$Comparison <- rownames(results_df)

# Reorder columns
results_df <- results_df %>% dplyr::select(Comparison, everything())

# Filter to keep only the first comparison result (ignoring reversed comparisons)
results_df <- results_df %>%
  filter(!grepl("vs", Comparison) | !duplicated(gsub("vs.*", "", Comparison)))

# Create flextable
fancy_table2 <- flextable(results_df)
fancy_table2 <- set_table_properties(fancy_table2, width = 0.8, layout = "autofit")

fancy_table2 <- set_caption(fancy_table2, caption = "Diagnosis of new categorical endpoints compared to case control status (gold standard) after excluding NCSU (N=173)")

fancy_table2 <- fontsize(fancy_table2, size = 8, part = "all") # Reduce font size of values
fancy_table2 <- fontsize(fancy_table2, size = 9, part = "header") # Reduce font size of header

# Print flextable
print(fancy_table2)

###
doc <- read_docx()
doc <- body_add_flextable(doc, fancy_table)
doc <- body_add_par(doc, value = " ", style = "Normal")
doc <- body_add_par(doc, value = " ", style = "Normal")

doc <- body_add_flextable(doc, fancy_table1)
doc <- body_add_par(doc, value = " ", style = "Normal")
doc <- body_add_par(doc, value = " ", style = "Normal")
doc <- body_add_flextable(doc, fancy_table2)

print(doc, target = "Categorical endpoint diagnosis.docx")


############### scatter plot
results_df <- results_df %>% dplyr::select(-Kappa)

results_long <- results_df %>%
  pivot_longer(cols = -Comparison, names_to = "Metric", values_to = "Value")

results_long <- results_long %>%
  mutate(Value = as.numeric(Value)) %>%
  filter(!is.na(Value)) 

new_labels <- c(
  "cirrhosis vs cirrhosis diagnosed" = "cirrhosis by ast/alt>1",
  "highest cut alt vs cirrhosis diagnosed" = "highest cut alt",
  "lowest cut alt vs cirrhosis diagnosed" = "lowest cut alt",
  "highest cut ast vs cirrhosis diagnosed" = "highest cut ast",
  "lowest cut ast vs cirrhosis diagnosed" = "lowest cut ast"
)

palette_colors <- brewer.pal(n = length(unique(results_long$Comparison)), name = "Set1")  

# Recode the Comparison column
results_long <- results_long %>%
  mutate(Comparison = recode(Comparison, !!!new_labels))



# Create the scatter plot
ggplot(results_long, aes(x = Value, y = Metric, color = Comparison, shape = Comparison)) +
  geom_point(size = 3) +
  labs(title = "Diagnostic testing after excluding NCSU",
       x = "Scores",
       y = "Measure of diagnostic test performance",
       color = "Comparison",
       shape = "Comparison") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) + # Adjust x-axis
  theme(axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.title = element_text(size = 12),
        legend.position = "right") +
  scale_shape_manual(values = 1:length(unique(results_long$Comparison))) +
  scale_color_manual(values = palette_colors)




```

# Correlation heat map btw PFAS and potential confounders
```{r}
# reset up reference category of some potential confounders
vars_to_convert <- c("source", "race_final_label","sq_drink_alcohol","sq_average_drink_per_day")
data[vars_to_convert] <- lapply(data[vars_to_convert], as.factor)

data$source <- relevel(data$source, ref = "Emory")
data$race_final_label <- relevel(data$race_final_label, ref = "White")
data$sq_drink_alcohol <- relevel(data$sq_drink_alcohol, ref = "No, never drinker")
data$sq_average_drink_per_day <- relevel(data$sq_average_drink_per_day, ref = "Less than 1 alcoholic drink per day")

# Define continuous potential confounders
numeric_data <- data %>%
     dplyr::select(all_of(potential_conf)) %>%
     dplyr::select_if(is.numeric)

conti_conf <- names(numeric_data)

# Function to extract model summary for continuous covariates
extract_model_summary <- function(pfas, covariate, data) {
  model <- lm(as.formula(paste(pfas, "~", covariate)), data = data)
  summary_model <- summary(model)
  estimate <- coef(summary_model)[2, 1]
  p_value <- coef(summary_model)[2, 4]
  return(data.frame(Confounders = covariate, Coeff = estimate, P = p_value, Factor = covariate, PFAS = pfas))
}

# Apply to all PFAS variables and continuous covariates
continuous_results <- bind_rows(lapply(pfas_name_scld, function(pfas) {
  bind_rows(lapply(conti_conf, function(cov) extract_model_summary(pfas, cov, data)))
}))

# Print continuous results
print(continuous_results)

# Define categorical confounders
cate_conf <- setdiff(potential_conf, conti_conf)

data <- data %>%
  mutate(across(all_of(cate_conf), as.factor))

# Function to fit model and handle categorical variables
fit_model_cat <- function(pfas, covariate, data) {
  model <- lm(as.formula(paste(pfas, "~", covariate)), data = data)
  summary_model <- summary(model)
  coefficients_df <- as.data.frame(summary_model$coefficients)
  coefficients_df <- coefficients_df[-1, ]  # Exclude intercept

  results <- data.frame()

  for (i in 1:nrow(coefficients_df)) {
    current_result <- data.frame(
      Confounders = covariate, 
      Coeff = coefficients_df[i, "Estimate"], 
      P = coefficients_df[i, "Pr(>|t|)"],
      Factor = rownames(coefficients_df)[i],
      PFAS = pfas
    )
    results <- rbind(results, current_result)
  }
  
  return(results)
}

# Apply to all PFAS variables and categorical covariates
categorical_results <- bind_rows(lapply(pfas_name_scld, function(pfas) {
  bind_rows(lapply(cate_conf, function(cov) fit_model_cat(pfas, cov, data)))
}))

# Print categorical results
print(categorical_results)

# Combine and print all results
all_results <- rbind(continuous_results, categorical_results)
print(all_results)

##
ggplot(all_results, aes(x = "", y = Coeff)) +
  geom_boxplot(fill = "lightblue", color = "blue") +
  labs(title = "Box Plot of Coefficients", y = "Coefficient") +
  theme_minimal()   
##


all_results <- all_results %>%
  mutate(
    
    P = ifelse(P < 0.0001, "<0.0001", 
                ifelse(P < 0.001, "<0.001", sprintf("%.3f", P)))
  ) %>%
  
  arrange(PFAS) %>%
  dplyr::select(PFAS, Confounders, Factor, Coeff, P)

# Convert all_results to a fancy table
fancy_table <- flextable(all_results) %>%
  set_table_properties(width = 0.8, layout = "autofit") %>%
  set_header_labels(values = c(
    Confounders = "Potential confounders", 
    Coeff = "Coefficients", 
    P = "P", 
    Factor = "Factors", 
    PFAS = "PFAS"
  )) %>%
  fontsize(size = 10, part = "all")

# Print the fancy table
print(fancy_table)

# Create a new Word document
doc <- read_docx()

# Add the first flextable
doc <- body_add_flextable(doc, value = fancy_table)

# Save the document
print(doc, target = "correlation coefficient between PFAS and potential confounders.docx")

# 1. Extract unique factors and PFAS
unique_factors <- unique(all_results$Factor)
unique_pfas <- unique(all_results$PFAS)
# 2. Create an empty matrix
result_matrix <- matrix(NA, nrow = length(unique_factors), ncol = length(unique_pfas))
rownames(result_matrix) <- unique_factors
colnames(result_matrix) <- unique_pfas

# 3. Fill the matrix with coefficients
for (i in seq_len(nrow(all_results))) {
  factor <- all_results$Factor[i]
  pfas <- all_results$PFAS[i]
  coeff <- all_results$Coeff[i]
  result_matrix[factor, pfas] <- coeff
}

# Convert to data frame for better handling
result_df <- as.data.frame(result_matrix)

# Print the result
print(result_df)

# Filter out rows with Factor containing "Unknown/Not Reported"
result_df_filtered <- result_df[!grepl("Unknown/Not Reported", rownames(result_df)), ]
print(result_df_filtered)

new_names <- c(
  "pf_hx_s_scld" = "PFHxS",
  "pf_un_a_scld" = "PFUnA",
  "pf_hp_a_scld" = "PFHpA",
  "pf_hp_s_scld" = "PFHpS",
  "pf_do_a_scld" = "PFDoA",
  "pfda_scld" = "PFDA",
  "pfna_scld" = "PFNA",
  "pfos_scld" = "PFOS",
  "pfoa_scld" = "PFOA",
  "pfba_scld" = "PFBA",
  "pfbs_scld" = "PFBS",
  "pf_pe_s_scld" = "PFPeS",
  "pf_pe_a_scld" = "PFPeA",
  "pf_hx_a_scld" = "PFHxA"
)

new_row_names <- c(
  "trig_mg_d_l" = "Triglyceride (mg/dl)",
  "age_at_enrollment" = "Age (years)",
  "bmi" = "BMI",
  "sourceDUKE" = "Duke vs Emory",
  "sourceNCSU" = "NCSU vs Emory",
  "sourceUNC" = "UNC vs Emory",
  "sexMale" = "Male vs Female",
  "race_eth_labelNHB" = "Nonhispanic Black vs Hispanic",
  "race_eth_labelNHO" = "Nonhispanic Other vs Hispanic",
  "race_eth_labelNHW" = "Nonhispanic White vs Hispanic",
  "race_final_labelMore than one race" = "More than one race vs White",
  "race_final_labelAmerican Indian" = "American Indian vs White",
  "race_final_labelAsian/Pacific Islander" = "Asian/Pacific Islander vs White",
  "race_final_labelOther" = "Other race vs White",
  "race_final_labelAsian" = "Asian vs White",
  "race_final_labelBlack" = "Black vs White",
  "race_final_labelAmerican Indian/Alaskan Native" = "American Indian/Alaskan Native vs White",
  "sq_water_wellYes" = "Water well, Yes vs No",
  "sq_water_other_typeYes" = "Water other type, Yes vs No",
  "sq_water_charcoal_filterYes" = "Water charcoal filter, Yes vs No",
  "sq_water_bottledYes" = "Water bottled, Yes vs No",
  "sq_water_faucet_filterYes" = "Water faucet filter, Yes vs No",
  "sq_water_tap_unfilteredYes" = "Water tap unfiltered, Yes vs No",
  "sq_water_house_filtrationYes" = "Water house filtration, Yes vs No",
  "sq_water_noneYes" = "water none, Yes vs No",
  
  "ethnicityNot Hispanic" = "NonHispanic vs Hispanic",
  "smokingSmoke or use vape" = "Smoking, Yes vs No",
  "sq_drink_alcoholNo, former drinker (stopped)" = "Past drinker vs Nondrinker",
  "sq_drink_alcoholYes, current drinker" = "Current drinker vs Nondrinker",
  "sq_average_drink_per_day1-2 alcoholic drinks per day" = "1-2/day vs <1/day alcoholic drinks",
  "sq_average_drink_per_day3-4 alcoholic drinks per day" = "3-4/day vs <1/day alcoholic drinks",
  "supp_meds_tylenolYes" = "Tylenol, Yes vs No",
  "supp_meds_steroidsYes" = "Steroids, Yes vs No",
  "sq_self_hep_cYes" = "Hepatitis C, Yes vs No",
  "sq_self_hep_bYes" = "Hepatitis B, Yes vs No",
  "ruralLiving in rural area" = "Rural vs Metro"
  
)

colnames(result_df_filtered) <- ifelse(colnames(result_df_filtered) %in% names(new_names), new_names[colnames(result_df_filtered)], colnames(result_df_filtered))

rownames(result_df_filtered) <- ifelse(rownames(result_df_filtered) %in% names(new_row_names), new_row_names[rownames(result_df_filtered)], rownames(result_df_filtered))


custom_colors <- colorRampPalette(brewer.pal(11, "RdYlBu"))(100)

pheatmap(result_df_filtered, 
         cluster_rows = TRUE, 
         cluster_cols = TRUE, 
         color = custom_colors,  # Use custom color palette
         display_numbers = FALSE,  # Hide values on the heatmap
         main = "Initial Heatmap of Coefficients",
         fontsize_row = 5,  # Adjust row label font size
         fontsize_col = 8   # Adjust column label font size
)


## Examine potential outliers
filtered_results <- all_results %>%
  filter(Coeff > 2) %>%
  dplyr::select(PFAS, Factor, Coeff)
print(filtered_results)

detect_outliers <- function(column) {
  q1 <- quantile(column, 0.25, na.rm = TRUE)
  q3 <- quantile(column, 0.75, na.rm = TRUE)
  iqr <- q3 - q1
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  outliers <- column[column < lower_bound | column > upper_bound]
  return(outliers)
}

outliers_list <- lapply(result_df, detect_outliers)

outliers_df <- do.call(rbind, lapply(names(outliers_list), function(col) {
  if (length(outliers_list[[col]]) > 0) {
    data.frame(PFAS = col, Coefficient = outliers_list[[col]])
  }
}))

print(outliers_df) #did not exclude these

# By emerging vs legacy PFAS
# Define the PFAS sets
first_set_pfas <- c("PFHxS", "PFUnA", "PFHpA", "PFHpS", "PFDoA", "PFDA", "PFNA", "PFOS", "PFOA")
second_set_pfas <- setdiff(colnames(result_df_filtered), first_set_pfas)

# Split the data into two dataframes
first_set_df <- result_df_filtered[, first_set_pfas, drop = FALSE]
second_set_df <- result_df_filtered[, second_set_pfas, drop = FALSE]

custom_colors <- colorRampPalette(brewer.pal(11, "RdYlBu"))(100)

# Generate heatmap for the first set of PFAS
pheatmap(first_set_df, 
         cluster_rows = TRUE, 
         cluster_cols = TRUE, 
         color = custom_colors,  # Use custom color palette from RColorBrewer
         display_numbers = FALSE,  # Hide values on the heatmap
         main = "Heatmap of Coefficients of Legacy PFAS",
         fontsize_row = 5,  # Adjust row label font size
         fontsize_col = 8   # Adjust column label font size
)


# Generate heatmap for the second set of PFAS
pheatmap(second_set_df, 
         cluster_rows = TRUE, 
         cluster_cols = TRUE, 
         color = custom_colors,  # Use custom color palette from RColorBrewer
         display_numbers = FALSE,  # Hide values on the heatmap
         main = "Heatmap of Coefficients of Emerging PFAS",
         fontsize_row = 5,  # Adjust row label font size
         fontsize_col = 8   # Adjust column label font size
)


```

# R squared and adjusted P
```{r}
#numeric confounders
numeric_data <- data %>%
     dplyr::select(all_of(potential_conf)) %>%
     dplyr::select_if(is.numeric)

conti_conf <- names(numeric_data)

extract_model_summary <- function(pfas, covariate, data) {
  model <- lm(as.formula(paste(pfas, "~", covariate)), data = data)
  summary_model <- summary(model)
  estimate <- coef(summary_model)[2, 1]
  se <- coef(summary_model)[2, 2]
  p_value <- coef(summary_model)[2, 4]
  r_squared <- summary_model$r.squared
  return(data.frame(Confounders = covariate, Coeff = estimate, SE = se, P = p_value, Factor = covariate, PFAS = pfas, R2 = r_squared))
}

continuous_results <- bind_rows(lapply(pfas_name_scld, function(pfas) {
  bind_rows(lapply(conti_conf, function(cov) extract_model_summary(pfas, cov, data)))
}))

print(continuous_results)

cate_conf <- setdiff(potential_conf, conti_conf)

data <- data %>%
  mutate(across(all_of(cate_conf), as.factor))

fit_model_cat <- function(pfas, covariate, data) {
  model <- lm(as.formula(paste(pfas, "~", covariate)), data = data)
  summary_model <- summary(model)
  coefficients_df <- as.data.frame(summary_model$coefficients)
  r_squared <- summary_model$r.squared
  coefficients_df <- coefficients_df[-1, ]  # Exclude intercept

  results <- data.frame()

  for (i in 1:nrow(coefficients_df)) {
    current_result <- data.frame(
      Confounders = covariate, 
      Coeff = coefficients_df[i, "Estimate"], 
      SE = coefficients_df[i, "Std. Error"],
      P = coefficients_df[i, "Pr(>|t|)"],
      Factor = rownames(coefficients_df)[i],
      PFAS = pfas,
      R2 = r_squared
    )
    results <- rbind(results, current_result)
  }
  
  return(results)
}

categorical_results <- bind_rows(lapply(pfas_name_scld, function(pfas) {
  bind_rows(lapply(cate_conf, function(cov) fit_model_cat(pfas, cov, data)))
}))

print(categorical_results)

all_results <- rbind(continuous_results, categorical_results)

adjust_pvalues <- function(df) {
  df %>%
    mutate(Adjusted_P = p.adjust(P, method = "bonferroni"))
}

all_results_adjusted <- all_results %>%
  group_by(PFAS) %>%
  group_modify(~ adjust_pvalues(.x)) %>%
  ungroup()

all_results_adjusted <- all_results_adjusted %>%
  mutate(significance = ifelse(Adjusted_P < 0.05, "*", ""))

all_results_adjusted <- all_results_adjusted %>%
  
  arrange(PFAS) %>%
  dplyr::select(PFAS, Confounders, Factor, Coeff, SE, P, Adjusted_P, R2, significance)

fancy_table <- flextable(all_results_adjusted) %>%
  set_table_properties(width = 0.8, layout = "autofit") %>%
  set_header_labels(values = c(
    Confounders = "Potential confounders", 
    Coeff = "Coefficients", 
    SE = "SE",
    P = "P", 
    Adjusted_P = "Adjusted P", 
    Factor = "Factors", 
    PFAS = "PFAS",
    R2 = "R-Squared",
    significance = "AdP<0.05"
  )) %>%
  fontsize(size = 10, part = "all")

print(fancy_table)

doc <- read_docx()
doc <- body_add_flextable(doc, value = fancy_table)
print(doc, target = "correlation coefficient between PFAS and potential confounders adding adjP and R2.docx")

# 1. Extract unique factors and PFAS
unique_conf <- unique(all_results_adjusted$Confounders)
unique_pfas <- unique(all_results_adjusted$PFAS)
# 2. Create an empty matrix
result_matrix <- matrix(NA, nrow = length(unique_conf), ncol = length(unique_pfas))
rownames(result_matrix) <- unique_conf
colnames(result_matrix) <- unique_pfas

significance_matrix <- matrix("", nrow = length(unique_conf), ncol = length(unique_pfas))
rownames(significance_matrix) <- unique_conf
colnames(significance_matrix) <- unique_pfas

# 3. Fill the matrix with coefficients
for (i in seq_len(nrow(all_results_adjusted))) {
  factor <- all_results_adjusted$Confounders[i]
  pfas <- all_results_adjusted$PFAS[i]
  r2 <- all_results_adjusted$R2[i]
  result_matrix[factor, pfas] <- r2
  sig <- all_results_adjusted$significance[i]
  significance_matrix[factor, pfas] <- sig
}

# Convert to data frame for better handling
result_df <- as.data.frame(result_matrix)

print(result_df)

old_par <- par(cex = 0.7) 
display.brewer.all()
par(old_par)

custom_colors <- colorRampPalette(brewer.pal(3, "RdYlBu"))(100)

new_names <- c(
  "pf_hx_s_scld" = "PFHxS",
  "pf_un_a_scld" = "PFUnA",
  "pf_hp_a_scld" = "PFHpA",
  "pf_hp_s_scld" = "PFHpS",
  "pf_do_a_scld" = "PFDoA",
  "pfda_scld" = "PFDA",
  "pfna_scld" = "PFNA",
  "pfos_scld" = "PFOS",
  "pfoa_scld" = "PFOA",
  "pfba_scld" = "PFBA",
  "pfbs_scld" = "PFBS",
  "pf_pe_s_scld" = "PFPeS",
  "pf_pe_a_scld" = "PFPeA",
  "pf_hx_a_scld" = "PFHxA"
)

new_row_names <- c(
  "trig_mg_d_l" = "Triglyceride (mg/dl)",
  "age_at_enrollment" = "Age (years)",
  "bmi" = "BMI",
  "source" = "Study site",
  "race_eth_label" = "Race and Ethnicity",
  "race_final_label" = "Race",
  "sq_water_well" = "Water well",
  "sq_water_other_type" = "Water other type",
  "sq_water_charcoal_filter" = "Water charcoal filter",
  "sq_water_bottled" = "Water bottled",
  "sq_water_faucet_filter" = "Water faucet filter",
  "sq_water_tap_unfiltered" = "Water tap unfiltered",
  "sq_water_house_filtration" = "Water house filtration",
  "sq_water_none" = "water none",
  "ethnicity" = "Ethnicity",
  "smoking" = "Smoking",
  "sq_drink_alcohol" = "Drinking history",
  "sq_average_drink_per_day" = "Drinking frequency",
  "supp_meds_tylenol" = "Tylenol",
  "supp_meds_steroids" = "Steroids",
  "sq_self_hep_c" = "Hepatitis C",
  "sq_self_hep_b" = "Hepatitis B",
  "rural" = "Living area"
  
)

colnames(result_df) <- ifelse(colnames(result_df) %in% names(new_names), new_names[colnames(result_df)], colnames(result_df))

rownames(result_df) <- ifelse(rownames(result_df) %in% names(new_row_names), new_row_names[rownames(result_df)], rownames(result_df))

# Generate heatmap with adjusted font size
pheatmap(result_df, 
         cluster_rows = TRUE, 
         cluster_cols = TRUE, 
         color = custom_colors,  # Use custom color palette
         display_numbers = significance_matrix,
         #display_numbers = FALSE,  # Hide values on the heatmap
         main = "R2 heatmap of linear regression",
         fontsize_row = 6,  # Adjust row label font size
         fontsize_col = 8   # Adjust column label font size
)


grid.text("R squared", x = 0.93, y = 0.87, gp = gpar(fontsize = 10))
grid.text("*adjusted P<0.05", x = 0.92, y = 0.20, gp = gpar(fontsize = 6, fontface = "italic"))

#####
# Forest plot for the correlation coefficient (SE)
sig_var <- c('age_at_enrollment', 'bmi','source','sq_average_drink_per_day','smoking','sq_water_bottled')

for_p <- all_results_adjusted[all_results_adjusted$Confounders %in% sig_var,]

# Filter out rows with Factor containing "Unknown/Not Reported"
for_p_filtered <- for_p[!grepl("Unknown/Not Reported", for_p$Factor), ]
print(for_p_filtered)

average_results <- for_p_filtered %>%
  group_by(Factor) %>%
  summarise(
    Average_Coeff = mean(Coeff, na.rm = TRUE),
    Average_SE = mean(SE, na.rm = TRUE)
  ) %>%
  arrange(Factor) 

print(average_results)
average_results<-cbind(average_results, PFAS_Group="Total")

for_p_filtered <- for_p_filtered %>%
  mutate(PFAS_Group = case_when(
    PFAS %in% legacy_scld ~ "Legacy",
    PFAS %in% emerging_scld ~ "Emerging"
  ))

average_by_group <- for_p_filtered %>%
  group_by(PFAS_Group, Factor) %>%
  summarise(
    Average_Coeff = mean(Coeff, na.rm = TRUE),
    Average_SE = mean(SE, na.rm = TRUE)
  ) %>%
  arrange(PFAS_Group, Factor)  # Optional: Sort by PFAS Group and Factor

print(average_by_group)

combined_mean<-rbind(average_results, average_by_group)

combined_mean <- combined_mean %>%
  mutate(Factor = factor(Factor, levels = unique(Factor)))

# Ensure that PFAS_Group is a factor with a specific order for plotting
combined_mean$PFAS_Group <- factor(combined_mean$PFAS_Group, levels = c("Total", "Legacy", "Emerging"))

combined_mean <- combined_mean %>%
  mutate(
    CI_Lower = Average_Coeff - 1.96 * Average_SE,
    CI_Upper = Average_Coeff + 1.96 * Average_SE
  )

combined_mean$Factor <- factor(combined_mean$Factor, levels = unique(combined_mean$Factor))

color_palette <- colorRampPalette(brewer.pal(3, "Set3"))(10)

new_sig_factor <- c(
  "sq_water_bottledYes" = "Water bottled, Yes vs No",
  "sq_average_drink_per_day3-4 alcoholic drinks per day" = "3-4/day vs <1/day alcholic drinks",
   "sq_average_drink_per_day1-2 alcoholic drinks per day" = "1-2/day vs <1/day alcholic drinks",
  "sourceUNC" = "UNC vs Emory",
  "sourceNCSU" = "NCSU vs Emory",
  "sourceDUKE" = "Duke vs Emory",
  "smokingSmoke or use vape" = "Smoker vs Nonsmoker",
  "bmi" = "BMI",
  "age_at_enrollment" = "Age"
)

combined_mean <- combined_mean %>%
  mutate(Factor = recode(Factor, !!!new_sig_factor))

custom_colors <- colorRampPalette(brewer.pal(3, "RdYlBu"))(100)

forest_plot <- ggplot(combined_mean, aes(x = Average_Coeff, y = Factor, color = Average_Coeff)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2) +
  scale_color_gradientn(colors = custom_colors) +
  labs(
    x = "Beta coefficient",
    y = "Confounders",
    color = "Coefficient",
    title = "Average Coefficients of Confounders by PFAS Group"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_text(size = 10),
    axis.title = element_text(size = 12)
  ) +
  facet_wrap(~ PFAS_Group, scales = "free_x", nrow = 1)

print(forest_plot)

# individual pfas
for_p_filtered <- for_p_filtered %>%
  mutate(
    CI_Lower = Coeff - 1.96 * SE,
    CI_Upper = Coeff + 1.96 * SE
  )

new_names <- c(
  "pf_hx_s_scld" = "PFHxS",
  "pf_un_a_scld" = "PFUnA",
  "pf_hp_a_scld" = "PFHpA",
  "pf_hp_s_scld" = "PFHpS",
  "pf_do_a_scld" = "PFDoA",
  "pfda_scld" = "PFDA",
  "pfna_scld" = "PFNA",
  "pfos_scld" = "PFOS",
  "pfoa_scld" = "PFOA",
  "pfba_scld" = "PFBA",
  "pfbs_scld" = "PFBS",
  "pf_pe_s_scld" = "PFPeS",
  "pf_pe_a_scld" = "PFPeA",
  "pf_hx_a_scld" = "PFHxA"
)

for_p_filtered <- for_p_filtered %>%
  mutate(PFAS = recode(PFAS, !!!new_names)) %>%
  mutate(Factor = recode(Factor, !!!new_sig_factor))

forest_plot <- ggplot(for_p_filtered, aes(x = Coeff, y = Factor, color = Coeff)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2) +
  scale_color_gradientn(colors = custom_colors) +
  labs(
    x = "Beta coefficient",
    y = "Confounders",
    color = "Coefficient",
    title = "Coefficients of Confounders by individual PFAS"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_text(size = 10),
    axis.title = element_text(size = 12)
  ) +
  facet_wrap(~ PFAS, scales = "free_x", nrow = 1)

print(forest_plot)

```

# correlation between potential confounders and endpoints
```{r}
extract_model_summary <- function(end, covariate, data) {
  model <- lm(as.formula(paste(end, "~", covariate)), data = data)
  summary_model <- summary(model)
  estimate <- coef(summary_model)[2, 1]
  se <- coef(summary_model)[2, 2]
  p_value <- coef(summary_model)[2, 4]
  r_squared <- summary_model$r.squared
  return(data.frame(Confounders = covariate, Coeff = estimate, SE = se, P = p_value, Factor = covariate, Endpoint = end, R2 = r_squared))
}
con_end <- c('log_alt','log_ast')
continuous_results <- bind_rows(lapply(con_end, function(end) {
  bind_rows(lapply(conti_conf, function(cov) extract_model_summary(end, cov, data)))
}))

print(continuous_results)

extract_model_summary <- function(end, covariate, data) {
  model <- glm(as.formula(paste(end, "~", covariate)), family = binomial, data = data)
  summary_model <- summary(model)
  estimate <- coef(summary_model)[2, 1]
  se <- coef(summary_model)[2, 2]
  p_value <- coef(summary_model)[2, 4]
  r_squared <- NA  # R-squared is not directly applicable to logistic regression models
  return(data.frame(Confounders = covariate, Coeff = estimate, SE = se, P = p_value, Factor = covariate, Endpoint = end, R2 = r_squared))
}

con_end1 <- c('alt_cat1','alt_cat2', 'ast_cat1','ast_cat2')
data_temp <- data %>%
  mutate(across(all_of(con_end1), ~ ifelse(. == "Normal", 0, 1)))

continuous_results1 <- bind_rows(lapply(con_end1, function(end) {
  bind_rows(lapply(conti_conf, function(cov) extract_model_summary(end, cov, data_temp)))
}))

print(continuous_results1)

continuous_results<-rbind(continuous_results, continuous_results1)

fit_model_cat <- function(end, covariate, data) {
  model <- lm(as.formula(paste(end, "~", covariate)), data = data)
  summary_model <- summary(model)
  coefficients_df <- as.data.frame(summary_model$coefficients)
  r_squared <- summary_model$r.squared
  coefficients_df <- coefficients_df[-1, ]  # Exclude intercept

  results <- data.frame()

  for (i in 1:nrow(coefficients_df)) {
    current_result <- data.frame(
      Confounders = covariate, 
      Coeff = coefficients_df[i, "Estimate"], 
      SE = coefficients_df[i, "Std. Error"],
      P = coefficients_df[i, "Pr(>|t|)"],
      Factor = rownames(coefficients_df)[i],
      Endpoint = end,
      R2 = r_squared
    )
    results <- rbind(results, current_result)
  }
  
  return(results)
}

categorical_results <- bind_rows(lapply(con_end, function(end) {
  bind_rows(lapply(cate_conf, function(cov) fit_model_cat(end, cov, data)))
}))

fit_model_cat <- function(end, covariate, data) {
  model <- glm(as.formula(paste(end, "~", covariate)), family = binomial, data = data)
  summary_model <- summary(model)
  coefficients_df <- as.data.frame(summary_model$coefficients)
  
  if (nrow(coefficients_df) < 2) {
    return(data.frame())
  }
  
  pseudo_r_squared <- 1 - summary_model$deviance / summary_model$null.deviance
  coefficients_df <- coefficients_df[-1, ]  # Exclude intercept

  results <- data.frame()

  for (i in 1:nrow(coefficients_df)) {
    current_result <- data.frame(
      Confounders = covariate, 
      Coeff = coefficients_df[i, "Estimate"], 
      SE = coefficients_df[i, "Std. Error"],
      P = coefficients_df[i, "Pr(>|z|)"],  # For logistic regression
      Factor = rownames(coefficients_df)[i],
      Endpoint = end,
      R2 = pseudo_r_squared
    )
    results <- rbind(results, current_result)
  }
  
  return(results)
}

categorical_results1 <- bind_rows(lapply(con_end1, function(end) {
  bind_rows(lapply(cate_conf, function(cov) fit_model_cat(end, cov, data_temp)))
}))

print(categorical_results1)

categorical_results<-rbind(categorical_results, categorical_results1)

all_results <- rbind(continuous_results, categorical_results)

adjust_pvalues <- function(df) {
  df %>%
    mutate(Adjusted_P = p.adjust(P, method = "bonferroni"))
}

all_results_adjusted <- all_results %>%
  group_by(Endpoint) %>%
  group_modify(~ adjust_pvalues(.x)) %>%
  ungroup()

all_results_adjusted <- all_results_adjusted %>%
  mutate(significance = ifelse(Adjusted_P < 0.05, "*", ""))

all_results_adjusted <- all_results_adjusted %>%
  #mutate(Endpoint = factor(Endpoint)) %>%
  arrange(Endpoint) %>%
  dplyr::select(Endpoint, Confounders, Factor, Coeff, SE, P, Adjusted_P, R2, significance)

fancy_table <- flextable(all_results_adjusted) %>%
  set_table_properties(width = 0.8, layout = "autofit") %>%
  set_header_labels(values = c(
    Confounders = "Potential confounders", 
    Coeff = "Coefficients", 
    SE = "SE",
    P = "P", 
    Adjusted_P = "Adjusted P", 
    Factor = "Factors", 
    Endpoint = "Endpoint",
    R2 = "R-Squared",
    significance = "AdP<0.05"
  )) %>%
  fontsize(size = 10, part = "all")

print(fancy_table)

doc <- read_docx()
doc <- body_add_flextable(doc, value = fancy_table)
print(doc, target = "Beta coefficient between potential confounders and categorical ast or alt adding adjP and R2.docx")

# 1. Extract unique factors and PFAS
unique_conf <- unique(all_results_adjusted$Confounders)
unique_end <- unique(all_results_adjusted$Endpoint)
# 2. Create an empty matrix
result_matrix <- matrix(NA, nrow = length(unique_conf), ncol = length(unique_end))
rownames(result_matrix) <- unique_conf
colnames(result_matrix) <- unique_end

significance_matrix <- matrix("", nrow = length(unique_conf), ncol = length(unique_end))
rownames(significance_matrix) <- unique_conf
colnames(significance_matrix) <- unique_end

# 3. Fill the matrix with coefficients
for (i in seq_len(nrow(all_results_adjusted))) {
  factor <- all_results_adjusted$Confounders[i]
  endpoint <- all_results_adjusted$Endpoint[i]
  r2 <- all_results_adjusted$R2[i]
  result_matrix[factor, endpoint] <- r2
  sig <- all_results_adjusted$significance[i]
  significance_matrix[factor, endpoint] <- sig
}

# Convert to data frame for better handling
result_df <- as.data.frame(result_matrix)

print(result_df)

custom_colors <- colorRampPalette(brewer.pal(3, "RdYlBu"))(100)

new_names <- c(
  "log_alt" = "Natural Log ALT",
  "log_ast" = "Natural Log AST",
  "ast_cat2" = "AST with highest cut",
  "ast_cat1" = "AST with lowest cut",
  "alt_cat2" = "ALT with highest cut",
  "alt_cat1" = "ALT with lowest cut"
)

new_row_names <- c(
  "trig_mg_d_l" = "Triglyceride (mg/dl)",
  "age_at_enrollment" = "Age (years)",
  "bmi" = "BMI",
  "race_final_label" = "Detailed race",
  "sq_water_well" = "Water well",
  "sq_water_other_type" = "Water other type",
  "sq_water_charcoal_filter" = "Water charcoal filter",
  "sq_water_bottled" = "Water bottled",
  "sq_water_faucet_filter" = "Water faucet filter",
  "sq_water_tap_unfiltered" = "Water tap unfiltered",
  "sq_water_house_filtration" = "Water house filtration",
  "sq_water_none" = "water none",
  "race_eth_label" = "Race ethnicity",
  "ethnicity" = "Ethnicity",
  "smoking" = "Smoking",
  "sq_drink_alcohol" = "Drinking history",
  "sq_average_drink_per_day" = "Frequency of alcoholic drinks per day",
  "supp_meds_tylenol" = "Tylenol",
  "supp_meds_steroids" = "Steroids",
  "sq_self_hep_c" = "Hepatitis C",
  "sq_self_hep_b" = "Hepatitis B",
  "source" = "Study site",
  "rural" = "Living area",
  "sex" = "Sex"
)

colnames(result_df) <- ifelse(colnames(result_df) %in% names(new_names), new_names[colnames(result_df)], colnames(result_df))

rownames(result_df) <- ifelse(rownames(result_df) %in% names(new_row_names), new_row_names[rownames(result_df)], rownames(result_df))

# Generate heatmap with adjusted font size
pheatmap(result_df, 
         cluster_rows = TRUE, 
         cluster_cols = TRUE, 
         color = custom_colors,  # Use custom color palette
         display_numbers = significance_matrix,
         #display_numbers = FALSE,  # Hide values on the heatmap
         main = "R2 heatmap on potential confounders and endpoints",
         fontsize_row = 6,  # Adjust row label font size
         fontsize_col = 8   # Adjust column label font size
)


grid.text("R squared", x = 0.93, y = 0.87, gp = gpar(fontsize = 10))
grid.text("*adjusted P<0.05", x = 0.92, y = 0.18, gp = gpar(fontsize = 6, fontface = "italic"))

#####
# Forest plot for the correlation coefficient (SE)
sig_var <- c('sex', 'source','trig_mg_d_l')

for_p <- all_results_adjusted[all_results_adjusted$Confounders %in% sig_var,]

# Filter out rows with Factor containing "Unknown/Not Reported"
for_p_filtered <- for_p[!grepl("Unknown/Not Reported", for_p$Factor), ]
print(for_p_filtered)

for_p_filtered$Factor <- factor(for_p_filtered$Factor, levels = unique(for_p_filtered$Factor))

color_palette <- colorRampPalette(brewer.pal(3, "Set3"))(10)

new_sig_factor <- c(
  "sexMale" = "Male vs Female",
  "sourceUNC" = "UNC vs Emory",
  "sourceNCSU" = "NCSU vs Emory",
  "sourceDUKE" = "Duke vs Emory",
  "smokingSmoke or use vape" = "Smoker vs Nonsmoker",
  "trig_mg_d_l" = "Triglyceride (mg/dL)"
)

new_for_p <- for_p_filtered %>%
  mutate(Factor = recode(Factor, !!!new_sig_factor)) %>%
  mutate(Endpoint =recode(Endpoint, !!!new_names))

cont_end<-c('Natural Log ALT', 'Natural Log AST')
cate_end<- setdiff(new_names, cont_end)

new_for_p_cont <- new_for_p[new_for_p$Endpoint %in% cont_end, ]
new_for_p_cat <- new_for_p[new_for_p$Endpoint %in% cate_end,]

# continuous endpoint forest plot
new_for_p_cont <- new_for_p_cont %>%
  mutate(
    CI_Lower = Coeff - 1.96 * SE,
    CI_Upper = Coeff + 1.96 * SE,

  )

forest_plot <- ggplot(new_for_p_cont, aes(x = Coeff, y = Factor, color = Coeff)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2) +
  scale_color_gradientn(colors = color_palette) +
  labs(
    x = "Coefficients",
    y = "Confounders",
    color = "Coefficients",
    title = "Coefficients of Potential Confounders with Endpoints"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_text(size = 10),
    axis.title = element_text(size = 12)
  ) +
  facet_wrap(~ Endpoint, scales = "free_x", nrow = 1)

print(forest_plot)

# categorical endpoint forest plot
new_for_p_cat <- new_for_p_cat %>%
  mutate(
    CI_Lower = Coeff - 1.96 * SE,
    CI_Upper = Coeff + 1.96 * SE,
    OR = exp(Coeff),
    OR_CI_Lower = exp(CI_Lower),
    OR_CI_Upper = exp(CI_Upper)
  )

forest_plot <- ggplot(new_for_p_cat, aes(x = OR, y = Factor, color = OR)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = OR_CI_Lower, xmax = OR_CI_Upper), height = 0.2) +
  scale_color_gradientn(colors = color_palette) +
  labs(
    x = "Odds Ratios",
    y = "Confounders",
    color = "Odds Ratios",
    title = "Odds Ratios of Potential Confounders with Endpoints"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_text(size = 10),
    axis.title = element_text(size = 12)
  ) +
  facet_wrap(~ Endpoint, scales = "free_x", nrow = 1)

print(forest_plot)

```













